services:
  # ---------------------
  # Cube.js (Semantic Layer / Analytical Backend)
  # ---------------------
  cubejs:
    image: cubejs/cube:latest # Official Cube.js image
    container_name: cubejs # Explicit container name for easier referencing
    env_file:
      - ${CUBEJS_ENV_FILE} # Contains DB name, user, and password for Cube.js
    build:
      context: ./cubejs # Optional: build Cube.js from local Dockerfile (custom setup)
    networks:
      - vero # Shared network for inter-service communication
    ports:
      - "15432:15432" # Cube SQL API using PostgreSQL wire protocol
    healthcheck:
      test: ["CMD", "curl", "-f", "http://cubejs:4000/readyz"] # Healthcheck for Cube.js
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    volumes:
      - ./cubejs/model:/cube/conf/model:rw # Mount data models (schemas)
      - ./cubejs/views:/cube/conf/model/views:rw # Mount view definitions
    depends_on:
      data-warehouse: # Cube.js requires the PostgreSQL data warehouse to be running first
        condition: service_healthy # cubejs will only start once data-warehouse is healthy

  # ---------------------
  # PostgreSQL (Data Warehouse for Cube.js)
  # ---------------------
  data-warehouse:
    image: postgres:16 # Official PostgreSQL image
    container_name: data-warehouse
    build:
      context: ./db # Optional: use a custom Dockerfile or init scripts
    networks:
      - vero
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d vero-demo-db"]
      interval: 10s
      timeout: 5s
      retries: 5
    env_file:
      - ${WAREHOUSE_ENV_FILE} # Contains DB name, user, and password for Cube.js
    volumes:
      - data-warehouse-db-data:/var/lib/postgresql/data # Persistent storage for PostgreSQL data

  # ---------------------
  # MCP Server (Custom AI Agent / API Middleware)
  # ---------------------
  mcp-server:
    container_name: mcp-server
    build:
      context: ./mcp-server # Custom backend build context
    depends_on:
      cubejs:
        condition: service_healthy # MCP will only start once Cube.js is healthy
    restart: on-failure # Auto-restart if the container crashes
    networks:
      - vero
    ports:
      - "9000:9000" # MCP Server API port for SSE and AI middleware
    env_file:
      - ${MCP_ENV_FILE} # Dev environment config (includes secret tokens, etc.)
    command: # Command-line args passed to the MCP process
      - --endpoint
      - ${MCP_ENDPOINT} # URL of the Cube.js backend
      - --api_secret
      - ${MCP_API_SECRET} # Secret used for authentication

  # ---------------------
  # Metabase (BI Dashboard / Analytics Frontend)
  # ---------------------
  metabase:
    image: stephaneturquay/metabase-arm64:latest # ARM64-compatible Metabase image
    container_name: metabase
    env_file:
      - ${METABASE_ENV_FILE} # Configuration for DB access, credentials, etc.
    depends_on:
      metabase-db:
        condition: service_healthy # Metabase starts after DB is ready
    volumes:
      - metabase-data:/metabase-data # Persistent Metabase application data
    networks:
      - vero

  # ---------------------
  # PostgreSQL for Metabase (stores application metadata and configs)
  # ---------------------
  metabase-db:
    image: postgres:13 # Stable, compatible version of PostgreSQL for Metabase
    container_name: metabase-db
    env_file:
      - ${METABASE_DB_ENV_FILE} # Username, password, and database name
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d metabase"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - metabase-db-data:/var/lib/postgresql/data # Persistent Metabase DB storage
    networks:
      - vero

  # ---------------------
  # Agno AI Agent (Streamlit-based interface for testing AI functions)
  # ---------------------
  agno:
    container_name: agno
    build:
      context: ./agno # Custom Streamlit agent build context
    volumes:
      - ./agno/src:/app/src # Mount source code into container
      - ./agno/logs:/app/logs # Persist logs outside container
    ports:
      - "8505:8505" # Streamlit server port for accessing the agent UI
    env_file:
      - ${AGNO_ENV_FILE} # OpenAI Key and MCP Server Connection
    networks:
      - vero

  # ---------------------
  # n8n Server
  # ---------------------
  n8n:
    container_name: n8n
    image: n8nio/n8n:latest
    build:
      context: ./n8n # Custom context
    env_file:
      - ${N8N_ENV_FILE} # n8n Configuration
    depends_on:
      n8n_db:
        condition: service_healthy
    volumes:
      - ./n8n-data:/home/node/.n8n
    networks:
      - vero
    healthcheck:
      test: ["CMD", "curl", "-f", "http://n8n:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s

  # ────────────────────────────────
  # n8n Database
  # ────────────────────────────────
  n8n_db:
    image: postgres:15
    container_name: n8n_db
    restart: unless-stopped
    env_file:
      - ${N8N_ENV_FILE} # n8n Configuration
    volumes:
      - n8n-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U n8n -d n8n"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - vero

  # ────────────────────────────────
  # NGINX reverse proxy for local dev
  # ────────────────────────────────
  nginx:
    image: nginxproxy/nginx-proxy
    container_name: nginx
    ports:
      - "80:80" # Expose HTTP
      - "443:443" # Expose HTTPS
      - "4000:4000" # Expose cubejs
      - "3000:3000" # Expose metabase
      - "5678:5678" # Expose n8n
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
      - ./nginx/logs:/var/log/nginx # Optional: Log access/errors
      - ./nginx/certs:/etc/nginx/certs:rw
      - ./nginx/acme:/etc/acme.sh:rw
      - ./nginx/vhost.d:/etc/nginx/vhost.d
      - ./nginx/html:/usr/share/nginx/html
    networks:
      - vero # Shared network for inter-service communication
    depends_on:
      cubejs: # requires the cubejs to be running first to mount the host
        condition: service_healthy
      n8n: # requires the n8n to be running first to mount the host
        condition: service_healthy

  # ---------------------
  # qdrant vector database for AI knowledge store
  # ---------------------
  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    container_name: qdrant
    env_file:
      - ${QDRANT_ENV_FILE} # qdrant Configuration
    ports:
      - 6333:6333
      - 6334:6334
    expose:
      - 6333 # For the HTTP API, for the Monitoring health and metrics endpoints
      - 6334 # For the gRPC API
    # - 6335 #  For Distributed deployment
    networks:
      - vero # Shared network for inter-service communication
    configs:
      - source: qdrant_config
        target: /qdrant/config/production.yaml
    volumes:
      - ./qdrant_data:/qdrant/storage

# ---------------------
# Volumes for Persistence
# ---------------------
volumes:
  metabase-db-data: # Volume for Metabase's PostgreSQL database
  metabase-data: # Volume for Metabase application state
  data-warehouse-db-data: # Volume for Cube.js PostgreSQL database
  n8n-data: # Volume for n8n instance
  n8n-db-data: # Volume for n8n's PostgreSQL database
  qdrant_data: # Volume for gdrant vector database

# ---------------------
# Shared Network
# ---------------------
networks:
  vero:
    driver: bridge # Bridge network for cross-service communication

configs:
  qdrant_config:
    content: |
      log_level: INFO
